{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Place Name</th>\n",
       "      <th>State</th>\n",
       "      <th>Origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Altdorf</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Named after Altdorf, Switzerland. [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Altorf</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>Named after Altdorf, Switzerland. [2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Altenburg</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>Named after Saxe-Altenburg. [3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anaheim</td>\n",
       "      <td>California</td>\n",
       "      <td>a blend of \"Ana\", after the nearby Santa Ana R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anhalt</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Named after the Principality of Anhalt. [5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>Wickenburg</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>Named after Henry Wickenburg, a Prussian prosp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>Wrangell</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>Named after Baltic German explorer Ferdinand v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>Zeigler</td>\n",
       "      <td>Illinois</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>Zell</td>\n",
       "      <td>Missouri</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>Zimmerman</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>367 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Place Name       State                                             Origin\n",
       "0       Altdorf   Wisconsin              Named after Altdorf, Switzerland. [1]\n",
       "1        Altorf    Illinois              Named after Altdorf, Switzerland. [2]\n",
       "2     Altenburg    Missouri                    Named after Saxe-Altenburg. [3]\n",
       "3       Anaheim  California  a blend of \"Ana\", after the nearby Santa Ana R...\n",
       "4        Anhalt       Texas        Named after the Principality of Anhalt. [5]\n",
       "..          ...         ...                                                ...\n",
       "362  Wickenburg     Arizona  Named after Henry Wickenburg, a Prussian prosp...\n",
       "363    Wrangell      Alaska  Named after Baltic German explorer Ferdinand v...\n",
       "364     Zeigler    Illinois                                                   \n",
       "365        Zell    Missouri                                                   \n",
       "366   Zimmerman   Minnesota                                                   \n",
       "\n",
       "[367 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/List_of_place_names_of_German_origin_in_the_United_States'\n",
    "html = urlopen(url) \n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "tables = soup.find_all('table')\n",
    "\n",
    "place_names = []\n",
    "states = []\n",
    "origin_notes = []\n",
    "place = []\n",
    "cells_holder = []\n",
    "\n",
    "for table in tables:\n",
    "    rows = table.find_all('tr')\n",
    "    #print(rows)\n",
    "    \n",
    "    for row in rows:\n",
    "        cells = row.find_all('td')\n",
    "        #cells_holder.append(cells)\n",
    "       # print(cells)\n",
    "        \n",
    "        if len(cells) > 1:\n",
    "            try:\n",
    "                place = cells[0]\n",
    "                place_names.append(place.text.strip())\n",
    "            except:\n",
    "                print()\n",
    "        \n",
    "            try:\n",
    "                state = cells[1]\n",
    "                states.append(state.text.strip())\n",
    "  \n",
    "            except:\n",
    "                print()\n",
    "            try:\n",
    "                origin_note = cells[2]\n",
    "                origin_notes.append(origin_note.text.strip())        \n",
    "            except:\n",
    "                print()\n",
    "    \n",
    "place_names = place_names[1:]\n",
    "states = states[1:]\n",
    "#print(place_names)\n",
    "#print(len(place_names))\n",
    "#print(len(states))\n",
    "#print(states)\n",
    "#print(len(origin_notes))\n",
    "#print(origin_notes)\n",
    "\n",
    "df_german_places = pd.DataFrame()\n",
    "df_german_places['Place Name'] = place_names\n",
    "df_german_places['State'] = states\n",
    "df_german_places['Origin'] = origin_notes\n",
    "df_german_places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\") ##Load available trained pipelines for English\n",
    "##########\n",
    "##########\n",
    "########Maybe add text prepprocessing\n",
    "\n",
    "\n",
    "#nlp = en_core_web_sm.load()\n",
    "listToStr = ' '.join([str(elem) for elem in origin_notes])\n",
    "doc = nlp(listToStr)\n",
    "#for ent in doc.ents:\n",
    "#    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Altdorf', 'Switzerland', 'Altdorf', 'Switzerland', 'Santa Ana River', 'Augsburg', 'Germany', 'Baden', 'Baden', 'Bavaria', 'Bavaria', 'Germany', 'Bavaria', 'Germany', 'Ault', 'Colorado', 'Genevra', 'California', 'Berlin', 'Otoe', 'Nebraska', 'Germany', 'Seattle', 'Great Britain', 'Germany', 'Karlsbad', 'Germany', 'Germany', 'Germany', 'Poland', 'Fischer', 'Flensburg', 'Germany', 'the Kingdom of Bavaria', 'Prussia', 'Prussia', 'Friedheim', 'Poland', 'Germany', 'Germany', 'Hamburg', 'Germany', 'Great Britain', 'Chicago', 'Jena', 'Germany', 'Karlsruhe', 'Germany', 'Germany', 'Washington Named', 'Lützen', 'Germany', 'Hohenlinden', 'Germany', 'Hector', 'New York Named', 'Minden', 'Germany', 'Rensselaer County Named', 'Germany', 'Baden', 'Germany', 'Berlin', 'Germany', 'Poland', 'Leipzig', 'Germany', 'Melle', 'Germany', 'South Stormont', 'Osnabrück', 'Germany', 'Germany', 'Pirc', 'Czech Republic', 'Potsdam', 'Germany', 'Germany', 'Schaumburg', 'United States', 'Georgia', 'United States', 'Denver', 'Colorado', 'Ulm', 'Germany', 'Vroman', 'Colorado', 'Westphalia', 'Germany']\n"
     ]
    }
   ],
   "source": [
    "## Load into pandas df\n",
    "df_extracted_original_places = pd.DataFrame()\n",
    "df_extracted_persons = pd.DataFrame()\n",
    "\n",
    "list_extracted_original_places=[]\n",
    "list_extracted_persons=[]\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == \"PERSON\":        \n",
    "        list_extracted_persons.append(ent.text)\n",
    "    elif ent.label_ == \"GPE\":\n",
    "        list_extracted_original_places.append(ent.text)\n",
    "print(list_extracted_original_places)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Germany                    29\n",
       "Baden                       3\n",
       "Colorado                    3\n",
       "Bavaria                     3\n",
       "Poland                      3\n",
       "Berlin                      2\n",
       "United States               2\n",
       "Altdorf                     2\n",
       "Switzerland                 2\n",
       "Prussia                     2\n",
       "Great Britain               2\n",
       "Melle                       1\n",
       "Chicago                     1\n",
       "Lützen                      1\n",
       "Karlsruhe                   1\n",
       "Nebraska                    1\n",
       "New York Named              1\n",
       "Minden                      1\n",
       "Jena                        1\n",
       "Denver                      1\n",
       "Friedheim                   1\n",
       "Pirc                        1\n",
       "Westphalia                  1\n",
       "Fischer                     1\n",
       "Ulm                         1\n",
       "Karlsbad                    1\n",
       "Otoe                        1\n",
       "Schaumburg                  1\n",
       "Hector                      1\n",
       "Hamburg                     1\n",
       "Hohenlinden                 1\n",
       "Osnabrück                   1\n",
       "Santa Ana River             1\n",
       "Ault                        1\n",
       "Leipzig                     1\n",
       "South Stormont              1\n",
       "Augsburg                    1\n",
       "Potsdam                     1\n",
       "Rensselaer County Named     1\n",
       "Washington Named            1\n",
       "Genevra                     1\n",
       "California                  1\n",
       "Czech Republic              1\n",
       "Seattle                     1\n",
       "the Kingdom of Bavaria      1\n",
       "Flensburg                   1\n",
       "Georgia                     1\n",
       "Vroman                      1\n",
       "Name: Original Places, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_extracted_original_places = pd.DataFrame({'Original Places': list_extracted_original_places})\n",
    "df_extracted_persons = pd.DataFrame({'Persons of Interest': list_extracted_persons})\n",
    "#df_extracted_original_places\n",
    "#df_extracted_persons\n",
    "df_extracted_persons['Persons of Interest'].value_counts()\n",
    "df_extracted_original_places['Original Places'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Steps\n",
    "##1. Extract persons\n",
    "##2. Find top 3 or so persons\n",
    "## Use suop on wiki\n",
    "## prepare texts\n",
    "## Loop through sentiment analyser and print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.381, 'neu': 0.273, 'pos': 0.346, 'compound': -0.0989}\n"
     ]
    }
   ],
   "source": [
    "## Test sentiment analyser\n",
    "## Could become function\n",
    "## Loop through websites text\n",
    "\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "## Simple NLTK sentiment intensity analyser function\n",
    "def nltk_sentiment_analyser(text):\n",
    "    input_txt = text\n",
    "    \n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    polscores=sia.polarity_scores(input_txt)\n",
    "    return polscores\n",
    "\n",
    "\n",
    "# Function call\n",
    "## TO BE ADJUSTED\n",
    "bla=\"Wow, NLTK is really shit!\"\n",
    "\n",
    "aa=nltk_sentiment_analyser(bla)\n",
    "print(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reinitialized existing Git repository in C:/Users/hgc24/OneDrive/Master_Data_Science/Data Science Master Class 1/ass3/.git/\n"
     ]
    }
   ],
   "source": [
    "## GIT Connect\n",
    "# Set remote origin\n",
    "!git init  \n",
    "#!git remote add origin https://github.com/HGC243/Assignment_3.git\n",
    "!git remote set-url origin https://github.com/HGC243/Assignment_3.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status:\n",
      "On branch master\n",
      "\n",
      "No commits yet\n",
      "\n",
      "Untracked files:\n",
      "  (use \"git add <file>...\" to include in what will be committed)\n",
      "\t.ipynb_checkpoints/\n",
      "\tAssessment 3_WebCrawler and NLP System_MA5851_SP82_2021.pdf\n",
      "\tAssignment_3_Code_Holger_Colin.ipynb\n",
      "\ttext.docx\n",
      "\n",
      "nothing added to commit but untracked files present (use \"git add\" to track)\n",
      "Files to add (This will be empty if there are no new files):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: LF will be replaced by CRLF in .ipynb_checkpoints/Assignment_3_Code_Holger_Colin-checkpoint.ipynb.\n",
      "The file will have its original line endings in your working directory\n",
      "warning: LF will be replaced by CRLF in Assignment_3_Code_Holger_Colin.ipynb.\n",
      "The file will have its original line endings in your working directory\n"
     ]
    }
   ],
   "source": [
    "# Check GIT Status\n",
    "print('Status:')\n",
    "!git status\n",
    "\n",
    "# Add files to GIT\n",
    "print('Files to add (This will be empty if there are no new files):')\n",
    "!git add ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
